{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "import hashlib\n",
    "import json\n",
    "import time\n",
    "from dbCon import PGCON\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data and use augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'imageRepo/ISICArchive_v1/train_224_224'\n",
    "validPath = 'imageRepo/ISICArchive_v1/validation_224_224'\n",
    "testPath = 'imageRepo/ISICArchive_v1/test_224_224'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataGen = ImageDataGenerator(1./255)\n",
    "testDataGen = ImageDataGenerator(1./255)\n",
    "validationDataGen = ImageDataGenerator(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9142 images belonging to 2 classes.\n",
      "Found 1144 images belonging to 2 classes.\n",
      "Found 1142 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainBatches = trainDataGen.flow_from_directory(\n",
    "    directory=trainPath, \n",
    "    target_size=(224,224), \n",
    "    classes=['benign', 'malignant'], \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validBatches = validationDataGen.flow_from_directory(\n",
    "    directory=validPath, \n",
    "    target_size=(224,224), \n",
    "    classes=['benign', 'malignant'], \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "testBatches = testDataGen.flow_from_directory(\n",
    "    directory=testPath, \n",
    "    target_size=(224,224), \n",
    "    classes=['benign', 'malignant'], \n",
    "    batch_size=32, \n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting functions for generating models with different hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelCreate(hyperParameters):\n",
    "    \"\"\"\n",
    "    Takes hyperparameter values as input, and generates a compiled model as output.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(\n",
    "        hyperParameters['numberOfConvFiltersInFirstLayer'],\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation='relu',\n",
    "        input_shape=(224,224,3))\n",
    "    )\n",
    "    \n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Add layers with convolutions\n",
    "    for i in range(1, hyperParameters['numberOfConvBlocks']+1):\n",
    "        # Add layers in each convolutions-block\n",
    "        for j in range(1, hyperParameters['numberOfConvLayersPerBlock']+1):\n",
    "            model.add(\n",
    "                Conv2D(filters=i*hyperParameters['numberOfConvFiltersInFirstLayer'], kernel_size=(3, 3), padding = 'same', activation='relu')\n",
    "            )\n",
    "        # Finish every block of convolutions with a max-pooling layer\n",
    "        model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten the data\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for k in range(1, hyperParameters['numberOfDenseLayerBlocks']+1):\n",
    "        model.add(Dropout(hyperParameters['dropOutInDenseLayer']))\n",
    "        model.add(Dense(units=64))\n",
    "    \n",
    "    \n",
    "    # Add the final layer, classification\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    \n",
    "    #'numberOfConvBlocks': 6, 'numberOfConvLayersPerBlock': 2, 'numberOfConvFiltersInFirstLayer': 32, 'numberOfDenseLayerBlocks': 3, 'dropOutInDenseLayer': 0.5, 'learningRate': 1e-05}\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hyperParameters['learningRate']), \n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomHyperparameters(hyperparameters):\n",
    "    \"\"\"\n",
    "    Takes a dict of hyperparameters and randomly chooses a set of parameters.\n",
    "    \"\"\"\n",
    "    hyperParametersToUse = {}\n",
    "    for hp, hpValues in hyperparameters.items():\n",
    "        hyperParametersToUse[hp] = random.choice(hpValues)\n",
    "    \n",
    "    return hyperParametersToUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHyperparameterSet(numberOfModels, hyperparameters):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    hyperparametersToUse = {}\n",
    "    i = 0\n",
    "    while i <= numberOfModels:\n",
    "    #for _ in range(0, numberOfModels):\n",
    "        getHyperparameters = getRandomHyperparameters(hyperparameters)\n",
    "        hpHash = hash(json.dumps(getHyperparameters, sort_keys=True))\n",
    "\n",
    "        # Only keep this combination of hyperparameters if unique\n",
    "        if not hpHash in hyperparametersToUse:\n",
    "            hyperparametersToUse[hpHash] = getHyperparameters\n",
    "            i += 1\n",
    "    return hyperparametersToUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for Random Search\n",
    "hyperparameters = {}\n",
    "hyperparameters['numberOfConvBlocks'] = [2,3,4,5,6]\n",
    "hyperparameters['numberOfConvLayersPerBlock'] = [1,2,3,4]\n",
    "hyperparameters['numberOfConvFiltersInFirstLayer'] = [32, 64, 128]\n",
    "hyperparameters['numberOfDenseLayerBlocks'] = [1,2,3,4]\n",
    "hyperparameters['dropOutInDenseLayer'] = [0.2, 0.3, 0.4, 0.5]\n",
    "hyperparameters['learningRate'] = [0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "# Pick hyperparameters to test\n",
    "numberOfModels = 25\n",
    "hyperparametersToUse = getHyperparameterSet(numberOfModels, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models and store the result in a local database for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 145s 504ms/step - loss: 0.7133 - accuracy: 0.5946 - val_loss: 0.5745 - val_accuracy: 0.6696\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 145s 506ms/step - loss: 0.5659 - accuracy: 0.7085 - val_loss: 0.5294 - val_accuracy: 0.7203\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.5263 - accuracy: 0.7343 - val_loss: 0.5029 - val_accuracy: 0.7421\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.4990 - accuracy: 0.7591 - val_loss: 0.4930 - val_accuracy: 0.7509\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.4834 - accuracy: 0.7650 - val_loss: 0.4858 - val_accuracy: 0.7753\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4700 - accuracy: 0.7740 - val_loss: 0.5076 - val_accuracy: 0.7212\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4717 - accuracy: 0.7721 - val_loss: 0.4715 - val_accuracy: 0.7762\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4566 - accuracy: 0.7770 - val_loss: 0.4653 - val_accuracy: 0.7753\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4363 - accuracy: 0.7901 - val_loss: 0.4645 - val_accuracy: 0.7579\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4396 - accuracy: 0.7879 - val_loss: 0.5061 - val_accuracy: 0.7351\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4371 - accuracy: 0.7927 - val_loss: 0.4713 - val_accuracy: 0.7710\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4128 - accuracy: 0.8066 - val_loss: 0.4560 - val_accuracy: 0.7657\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4140 - accuracy: 0.8092 - val_loss: 0.4561 - val_accuracy: 0.7780\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.4048 - accuracy: 0.8077 - val_loss: 0.4614 - val_accuracy: 0.7657\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3993 - accuracy: 0.8066 - val_loss: 0.4562 - val_accuracy: 0.7753\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3782 - accuracy: 0.8212 - val_loss: 0.4754 - val_accuracy: 0.7701\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3667 - accuracy: 0.8357 - val_loss: 0.4589 - val_accuracy: 0.7649\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3621 - accuracy: 0.8360 - val_loss: 0.4859 - val_accuracy: 0.7771\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3597 - accuracy: 0.8364 - val_loss: 0.4858 - val_accuracy: 0.7727\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3261 - accuracy: 0.8599 - val_loss: 0.5026 - val_accuracy: 0.7727\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.3201 - accuracy: 0.8603 - val_loss: 0.5202 - val_accuracy: 0.7806\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.2881 - accuracy: 0.8725 - val_loss: 0.5148 - val_accuracy: 0.7526\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.2768 - accuracy: 0.8835 - val_loss: 0.5431 - val_accuracy: 0.7815\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.2609 - accuracy: 0.8876 - val_loss: 0.5181 - val_accuracy: 0.7640\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.2353 - accuracy: 0.9030 - val_loss: 0.5996 - val_accuracy: 0.7649\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.2119 - accuracy: 0.9133 - val_loss: 0.5925 - val_accuracy: 0.7622\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 145s 508ms/step - loss: 0.1773 - accuracy: 0.9293 - val_loss: 0.6156 - val_accuracy: 0.7780\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1825 - accuracy: 0.9292 - val_loss: 0.6669 - val_accuracy: 0.7570\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1488 - accuracy: 0.9418 - val_loss: 0.7487 - val_accuracy: 0.7378\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1445 - accuracy: 0.9466 - val_loss: 0.6876 - val_accuracy: 0.7552\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1306 - accuracy: 0.9532 - val_loss: 0.7689 - val_accuracy: 0.7605\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1058 - accuracy: 0.9609 - val_loss: 0.7979 - val_accuracy: 0.7587\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1093 - accuracy: 0.9582 - val_loss: 0.8358 - val_accuracy: 0.7701\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0901 - accuracy: 0.9686 - val_loss: 0.8745 - val_accuracy: 0.7657\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.9575 - val_accuracy: 0.7465\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0792 - accuracy: 0.9717 - val_loss: 0.9172 - val_accuracy: 0.7614\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 145s 506ms/step - loss: 0.0759 - accuracy: 0.9694 - val_loss: 0.9280 - val_accuracy: 0.7675\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 145s 506ms/step - loss: 0.0678 - accuracy: 0.9755 - val_loss: 0.9765 - val_accuracy: 0.7509\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0666 - accuracy: 0.9731 - val_loss: 0.9815 - val_accuracy: 0.7701\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0598 - accuracy: 0.9780 - val_loss: 1.0355 - val_accuracy: 0.7614\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0578 - accuracy: 0.9788 - val_loss: 1.0649 - val_accuracy: 0.7622\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0473 - accuracy: 0.9833 - val_loss: 1.0642 - val_accuracy: 0.7552\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0654 - accuracy: 0.9759 - val_loss: 1.0738 - val_accuracy: 0.7579\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 1.2255 - val_accuracy: 0.7561\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0654 - accuracy: 0.9757 - val_loss: 1.1653 - val_accuracy: 0.7448\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 145s 506ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 1.1386 - val_accuracy: 0.7430\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0537 - accuracy: 0.9807 - val_loss: 1.1789 - val_accuracy: 0.7544\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 1.1207 - val_accuracy: 0.7614\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0458 - accuracy: 0.9829 - val_loss: 1.2199 - val_accuracy: 0.7421\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.0509 - accuracy: 0.9795 - val_loss: 1.1226 - val_accuracy: 0.7509\n",
      "1\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 79s 274ms/step - loss: 2.2658 - accuracy: 0.5624 - val_loss: 0.5740 - val_accuracy: 0.6862\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.6656 - accuracy: 0.6681 - val_loss: 0.5469 - val_accuracy: 0.7054\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.5797 - accuracy: 0.7062 - val_loss: 0.5380 - val_accuracy: 0.7325\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.5331 - accuracy: 0.7356 - val_loss: 0.5275 - val_accuracy: 0.6984\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.5255 - accuracy: 0.7418 - val_loss: 0.5215 - val_accuracy: 0.7010\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.5203 - accuracy: 0.7325 - val_loss: 0.4969 - val_accuracy: 0.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.5032 - accuracy: 0.7517 - val_loss: 0.4995 - val_accuracy: 0.7308\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4865 - accuracy: 0.7579 - val_loss: 0.4885 - val_accuracy: 0.7465\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4859 - accuracy: 0.7626 - val_loss: 0.4912 - val_accuracy: 0.7334\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4872 - accuracy: 0.7572 - val_loss: 0.4777 - val_accuracy: 0.7526\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4903 - accuracy: 0.7573 - val_loss: 0.4732 - val_accuracy: 0.7552\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 78s 274ms/step - loss: 0.4626 - accuracy: 0.7802 - val_loss: 0.4713 - val_accuracy: 0.7579\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4630 - accuracy: 0.7784 - val_loss: 0.4695 - val_accuracy: 0.7657\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4608 - val_accuracy: 0.7719\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4343 - accuracy: 0.7943 - val_loss: 0.4924 - val_accuracy: 0.7649\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4341 - accuracy: 0.7916 - val_loss: 0.4832 - val_accuracy: 0.7456\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4247 - accuracy: 0.7981 - val_loss: 0.4756 - val_accuracy: 0.7596\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4174 - accuracy: 0.8035 - val_loss: 0.4576 - val_accuracy: 0.7832\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.4024 - accuracy: 0.8043 - val_loss: 0.4706 - val_accuracy: 0.7622\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3944 - accuracy: 0.8149 - val_loss: 0.4774 - val_accuracy: 0.7509\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3764 - accuracy: 0.8292 - val_loss: 0.4687 - val_accuracy: 0.7736\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3836 - accuracy: 0.8239 - val_loss: 0.4684 - val_accuracy: 0.7815\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3588 - accuracy: 0.8413 - val_loss: 0.4880 - val_accuracy: 0.7605\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3674 - accuracy: 0.8346 - val_loss: 0.5016 - val_accuracy: 0.7622\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3432 - accuracy: 0.8517 - val_loss: 0.4790 - val_accuracy: 0.7736\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3282 - accuracy: 0.8529 - val_loss: 0.5026 - val_accuracy: 0.7631\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3346 - accuracy: 0.8493 - val_loss: 0.4889 - val_accuracy: 0.7666\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3125 - accuracy: 0.8632 - val_loss: 0.5158 - val_accuracy: 0.7491\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.3044 - accuracy: 0.8683 - val_loss: 0.5310 - val_accuracy: 0.7535\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2777 - accuracy: 0.8815 - val_loss: 0.5176 - val_accuracy: 0.7701\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2731 - accuracy: 0.8810 - val_loss: 0.5241 - val_accuracy: 0.7719\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2613 - accuracy: 0.8912 - val_loss: 0.5500 - val_accuracy: 0.7675\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2573 - accuracy: 0.8896 - val_loss: 0.5799 - val_accuracy: 0.7622\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2280 - accuracy: 0.9096 - val_loss: 0.5577 - val_accuracy: 0.7614\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2199 - accuracy: 0.9093 - val_loss: 0.5739 - val_accuracy: 0.7596\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.2042 - accuracy: 0.9205 - val_loss: 0.5922 - val_accuracy: 0.7736\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1876 - accuracy: 0.9226 - val_loss: 0.5967 - val_accuracy: 0.7640\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1752 - accuracy: 0.9294 - val_loss: 0.6252 - val_accuracy: 0.7684\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1821 - accuracy: 0.9274 - val_loss: 0.6081 - val_accuracy: 0.7640\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1477 - accuracy: 0.9445 - val_loss: 0.6970 - val_accuracy: 0.7692\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1377 - accuracy: 0.9484 - val_loss: 0.6780 - val_accuracy: 0.7701\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1331 - accuracy: 0.9462 - val_loss: 0.7116 - val_accuracy: 0.7587\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1235 - accuracy: 0.9577 - val_loss: 0.8371 - val_accuracy: 0.7649\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1151 - accuracy: 0.9570 - val_loss: 0.8037 - val_accuracy: 0.7710\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.0984 - accuracy: 0.9632 - val_loss: 0.8182 - val_accuracy: 0.7640\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.0991 - accuracy: 0.9637 - val_loss: 0.9200 - val_accuracy: 0.7596\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.1003 - accuracy: 0.9595 - val_loss: 0.8552 - val_accuracy: 0.7684\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.0916 - accuracy: 0.9629 - val_loss: 0.9028 - val_accuracy: 0.7675\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 78s 273ms/step - loss: 0.0834 - accuracy: 0.9719 - val_loss: 0.9103 - val_accuracy: 0.7596\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 78s 274ms/step - loss: 0.0797 - accuracy: 0.9717 - val_loss: 0.8723 - val_accuracy: 0.7500\n",
      "1\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 27s 92ms/step - loss: 0.6754 - accuracy: 0.5729 - val_loss: 0.5914 - val_accuracy: 0.6766\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.5791 - accuracy: 0.6986 - val_loss: 0.5468 - val_accuracy: 0.7054\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.5421 - accuracy: 0.7300 - val_loss: 0.5294 - val_accuracy: 0.7430\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.5291 - accuracy: 0.7360 - val_loss: 0.5075 - val_accuracy: 0.7491\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.5204 - accuracy: 0.7470 - val_loss: 0.4973 - val_accuracy: 0.7404\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.5060 - accuracy: 0.7534 - val_loss: 0.4831 - val_accuracy: 0.7605\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4799 - accuracy: 0.7756 - val_loss: 0.4834 - val_accuracy: 0.7483\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4828 - accuracy: 0.7701 - val_loss: 0.4876 - val_accuracy: 0.7351\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4763 - accuracy: 0.7726 - val_loss: 0.4710 - val_accuracy: 0.7762\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4720 - accuracy: 0.7745 - val_loss: 0.4670 - val_accuracy: 0.7701\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4619 - accuracy: 0.7816 - val_loss: 0.4686 - val_accuracy: 0.7544\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4661 - accuracy: 0.7768 - val_loss: 0.4566 - val_accuracy: 0.7710\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4645 - accuracy: 0.7803 - val_loss: 0.4694 - val_accuracy: 0.7745\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4505 - accuracy: 0.7863 - val_loss: 0.4651 - val_accuracy: 0.7561\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4542 - accuracy: 0.7842 - val_loss: 0.4781 - val_accuracy: 0.7806\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4334 - accuracy: 0.7956 - val_loss: 0.4502 - val_accuracy: 0.7780\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4553 - accuracy: 0.7850 - val_loss: 0.4617 - val_accuracy: 0.7675\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4315 - accuracy: 0.7939 - val_loss: 0.4468 - val_accuracy: 0.7797\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4330 - accuracy: 0.7995 - val_loss: 0.4558 - val_accuracy: 0.7876\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4347 - accuracy: 0.7992 - val_loss: 0.4515 - val_accuracy: 0.7710\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4262 - accuracy: 0.8037 - val_loss: 0.4406 - val_accuracy: 0.7762\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4190 - accuracy: 0.8046 - val_loss: 0.4419 - val_accuracy: 0.7797\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4204 - accuracy: 0.8121 - val_loss: 0.4431 - val_accuracy: 0.7841\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4249 - accuracy: 0.8029 - val_loss: 0.4535 - val_accuracy: 0.7753\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4185 - accuracy: 0.8040 - val_loss: 0.4547 - val_accuracy: 0.7753\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4151 - accuracy: 0.8089 - val_loss: 0.4480 - val_accuracy: 0.7771\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3984 - accuracy: 0.8207 - val_loss: 0.4388 - val_accuracy: 0.7876\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.4075 - accuracy: 0.8116 - val_loss: 0.4544 - val_accuracy: 0.7701\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3996 - accuracy: 0.8202 - val_loss: 0.4540 - val_accuracy: 0.7788\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3953 - accuracy: 0.8238 - val_loss: 0.4593 - val_accuracy: 0.7692\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3892 - accuracy: 0.8204 - val_loss: 0.4382 - val_accuracy: 0.7815\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3896 - accuracy: 0.8199 - val_loss: 0.4390 - val_accuracy: 0.7885\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3771 - accuracy: 0.8321 - val_loss: 0.4430 - val_accuracy: 0.7946\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3773 - accuracy: 0.8373 - val_loss: 0.4414 - val_accuracy: 0.7902\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3578 - accuracy: 0.8397 - val_loss: 0.4371 - val_accuracy: 0.7815\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3498 - accuracy: 0.8370 - val_loss: 0.4584 - val_accuracy: 0.7911\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3647 - accuracy: 0.8329 - val_loss: 0.4502 - val_accuracy: 0.7928\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3391 - accuracy: 0.8504 - val_loss: 0.4468 - val_accuracy: 0.7963\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3373 - accuracy: 0.8471 - val_loss: 0.4583 - val_accuracy: 0.7797\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3388 - accuracy: 0.8547 - val_loss: 0.4483 - val_accuracy: 0.7911\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3218 - accuracy: 0.8581 - val_loss: 0.4523 - val_accuracy: 0.7762\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3146 - accuracy: 0.8608 - val_loss: 0.4470 - val_accuracy: 0.7972\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.3089 - accuracy: 0.8694 - val_loss: 0.4764 - val_accuracy: 0.7911\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2959 - accuracy: 0.8705 - val_loss: 0.4678 - val_accuracy: 0.7850\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2951 - accuracy: 0.8744 - val_loss: 0.4610 - val_accuracy: 0.7885\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2854 - accuracy: 0.8792 - val_loss: 0.4755 - val_accuracy: 0.7911\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2687 - accuracy: 0.8884 - val_loss: 0.4785 - val_accuracy: 0.7797\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2715 - accuracy: 0.8850 - val_loss: 0.5093 - val_accuracy: 0.7867\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2551 - accuracy: 0.8923 - val_loss: 0.4929 - val_accuracy: 0.7780\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 26s 91ms/step - loss: 0.2390 - accuracy: 0.9068 - val_loss: 0.5305 - val_accuracy: 0.7893\n",
      "1\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 130s 451ms/step - loss: 0.6865 - accuracy: 0.5501 - val_loss: 0.6179 - val_accuracy: 0.6407\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 129s 451ms/step - loss: 0.6038 - accuracy: 0.6828 - val_loss: 0.5381 - val_accuracy: 0.7194\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 129s 451ms/step - loss: 0.5539 - accuracy: 0.7303 - val_loss: 0.5297 - val_accuracy: 0.7098\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 129s 451ms/step - loss: 0.5282 - accuracy: 0.7373 - val_loss: 0.4947 - val_accuracy: 0.7517\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 129s 451ms/step - loss: 0.5089 - accuracy: 0.7566 - val_loss: 0.4922 - val_accuracy: 0.7395\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 129s 451ms/step - loss: 0.4929 - accuracy: 0.7608 - val_loss: 0.4750 - val_accuracy: 0.7596\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 129s 451ms/step - loss: 0.4844 - accuracy: 0.7709 - val_loss: 0.4757 - val_accuracy: 0.7675\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4780 - accuracy: 0.7705 - val_loss: 0.4685 - val_accuracy: 0.7727\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4629 - accuracy: 0.7827 - val_loss: 0.4651 - val_accuracy: 0.7649\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4604 - accuracy: 0.7853 - val_loss: 0.4527 - val_accuracy: 0.7701\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4721 - accuracy: 0.7836 - val_loss: 0.4557 - val_accuracy: 0.7684\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4639 - accuracy: 0.7805 - val_loss: 0.4573 - val_accuracy: 0.7640\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4409 - accuracy: 0.7912 - val_loss: 0.4532 - val_accuracy: 0.7666\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.4414 - val_accuracy: 0.7719\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.4321 - accuracy: 0.8005 - val_loss: 0.5191 - val_accuracy: 0.7395\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.4425 - accuracy: 0.7983 - val_loss: 0.4481 - val_accuracy: 0.7832\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4308 - accuracy: 0.8044 - val_loss: 0.4415 - val_accuracy: 0.7745\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 129s 452ms/step - loss: 0.4181 - accuracy: 0.8099 - val_loss: 0.4461 - val_accuracy: 0.7788\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 129s 453ms/step - loss: 0.4160 - accuracy: 0.8088 - val_loss: 0.4652 - val_accuracy: 0.7745\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.4195 - accuracy: 0.8087 - val_loss: 0.4403 - val_accuracy: 0.7815\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.3866 - accuracy: 0.8237 - val_loss: 0.4324 - val_accuracy: 0.7876\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.3858 - accuracy: 0.8212 - val_loss: 0.4292 - val_accuracy: 0.7876\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.3691 - accuracy: 0.8301 - val_loss: 0.4387 - val_accuracy: 0.7867\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.3441 - accuracy: 0.8481 - val_loss: 0.4587 - val_accuracy: 0.7788\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.3334 - accuracy: 0.8548 - val_loss: 0.4587 - val_accuracy: 0.7911\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 129s 453ms/step - loss: 0.2978 - accuracy: 0.8760 - val_loss: 0.4757 - val_accuracy: 0.7736\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.2658 - accuracy: 0.8918 - val_loss: 0.5040 - val_accuracy: 0.7771\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.2454 - accuracy: 0.9006 - val_loss: 0.5265 - val_accuracy: 0.7928\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.1985 - accuracy: 0.9193 - val_loss: 0.5941 - val_accuracy: 0.7920\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.1661 - accuracy: 0.9359 - val_loss: 0.6199 - val_accuracy: 0.7797\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.1147 - accuracy: 0.9580 - val_loss: 0.7009 - val_accuracy: 0.7858\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.1085 - accuracy: 0.9583 - val_loss: 0.8342 - val_accuracy: 0.7500\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.1104 - accuracy: 0.9612 - val_loss: 0.8071 - val_accuracy: 0.7640\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0613 - accuracy: 0.9812 - val_loss: 0.8333 - val_accuracy: 0.7631\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0620 - accuracy: 0.9789 - val_loss: 1.0029 - val_accuracy: 0.7649\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0342 - accuracy: 0.9904 - val_loss: 0.8390 - val_accuracy: 0.7692\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 1.0177 - val_accuracy: 0.7657\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0466 - accuracy: 0.9841 - val_loss: 1.1187 - val_accuracy: 0.7806\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0520 - accuracy: 0.9830 - val_loss: 1.1294 - val_accuracy: 0.7815\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.9725 - val_accuracy: 0.7876\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 1.1895 - val_accuracy: 0.7745\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 1.4828 - val_accuracy: 0.7797\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 1.5859 - val_accuracy: 0.7780\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.9754 - val_accuracy: 0.7727\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0960 - accuracy: 0.9643 - val_loss: 1.1581 - val_accuracy: 0.7666\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 1.7086 - val_accuracy: 0.7500\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0864 - accuracy: 0.9737 - val_loss: 1.2395 - val_accuracy: 0.7719\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 1.2404 - val_accuracy: 0.7885\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0345 - accuracy: 0.9880 - val_loss: 1.3049 - val_accuracy: 0.7815\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 130s 453ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 1.1988 - val_accuracy: 0.7832\n",
      "1\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 22s 74ms/step - loss: 3.5881 - accuracy: 0.5397 - val_loss: 0.6224 - val_accuracy: 0.6871\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.8212 - accuracy: 0.6387 - val_loss: 0.5559 - val_accuracy: 0.6932\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.6268 - accuracy: 0.6748 - val_loss: 0.5336 - val_accuracy: 0.7150\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5765 - accuracy: 0.7056 - val_loss: 0.5289 - val_accuracy: 0.7107\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5376 - accuracy: 0.7276 - val_loss: 0.5237 - val_accuracy: 0.7290\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5407 - accuracy: 0.7288 - val_loss: 0.5178 - val_accuracy: 0.7334\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5137 - accuracy: 0.7411 - val_loss: 0.5075 - val_accuracy: 0.7404\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5190 - accuracy: 0.7428 - val_loss: 0.5091 - val_accuracy: 0.7483\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5130 - accuracy: 0.7373 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5031 - accuracy: 0.7492 - val_loss: 0.5029 - val_accuracy: 0.7413\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.5038 - accuracy: 0.7466 - val_loss: 0.5048 - val_accuracy: 0.7325\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4923 - accuracy: 0.7569 - val_loss: 0.5027 - val_accuracy: 0.7517\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4783 - accuracy: 0.7664 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4950 - accuracy: 0.7536 - val_loss: 0.4812 - val_accuracy: 0.7552\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4672 - accuracy: 0.7747 - val_loss: 0.4835 - val_accuracy: 0.7509\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4711 - accuracy: 0.7679 - val_loss: 0.5469 - val_accuracy: 0.6941\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4692 - accuracy: 0.7697 - val_loss: 0.4813 - val_accuracy: 0.7544\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4792 - accuracy: 0.7630 - val_loss: 0.4785 - val_accuracy: 0.7491\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4623 - accuracy: 0.7733 - val_loss: 0.4645 - val_accuracy: 0.7552\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4495 - accuracy: 0.7790 - val_loss: 0.4756 - val_accuracy: 0.7456\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4471 - accuracy: 0.7769 - val_loss: 0.4631 - val_accuracy: 0.7474\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4501 - accuracy: 0.7813 - val_loss: 0.4862 - val_accuracy: 0.7474\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4468 - accuracy: 0.7872 - val_loss: 0.4925 - val_accuracy: 0.7605\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4428 - accuracy: 0.7862 - val_loss: 0.4650 - val_accuracy: 0.7465\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4322 - accuracy: 0.7877 - val_loss: 0.4696 - val_accuracy: 0.7622\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4686 - val_accuracy: 0.7631\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4187 - accuracy: 0.7970 - val_loss: 0.4604 - val_accuracy: 0.7579\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4263 - accuracy: 0.7937 - val_loss: 0.4685 - val_accuracy: 0.7413\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4174 - accuracy: 0.8019 - val_loss: 0.4813 - val_accuracy: 0.7719\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4124 - accuracy: 0.8026 - val_loss: 0.4581 - val_accuracy: 0.7701\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4174 - accuracy: 0.8034 - val_loss: 0.4653 - val_accuracy: 0.7509\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4136 - accuracy: 0.7992 - val_loss: 0.4526 - val_accuracy: 0.7517\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3973 - accuracy: 0.8105 - val_loss: 0.4429 - val_accuracy: 0.7710\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.4049 - accuracy: 0.8096 - val_loss: 0.4484 - val_accuracy: 0.7684\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3948 - accuracy: 0.8118 - val_loss: 0.4831 - val_accuracy: 0.7631\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3908 - accuracy: 0.8099 - val_loss: 0.4350 - val_accuracy: 0.7806\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3892 - accuracy: 0.8116 - val_loss: 0.4452 - val_accuracy: 0.7710\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.4574 - val_accuracy: 0.7570\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3746 - accuracy: 0.8256 - val_loss: 0.4438 - val_accuracy: 0.7701\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3828 - accuracy: 0.8165 - val_loss: 0.4687 - val_accuracy: 0.7771\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3712 - accuracy: 0.8255 - val_loss: 0.4581 - val_accuracy: 0.7797\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3747 - accuracy: 0.8248 - val_loss: 0.4576 - val_accuracy: 0.7710\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3713 - accuracy: 0.8321 - val_loss: 0.4477 - val_accuracy: 0.7753\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3584 - accuracy: 0.8308 - val_loss: 0.4403 - val_accuracy: 0.7788\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3499 - accuracy: 0.8420 - val_loss: 0.4404 - val_accuracy: 0.7771\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 21s 74ms/step - loss: 0.3484 - accuracy: 0.8380 - val_loss: 0.4431 - val_accuracy: 0.7771\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3486 - accuracy: 0.8417 - val_loss: 0.4693 - val_accuracy: 0.7684\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3414 - accuracy: 0.8388 - val_loss: 0.4377 - val_accuracy: 0.7841\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3418 - accuracy: 0.8467 - val_loss: 0.4438 - val_accuracy: 0.7806\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 21s 73ms/step - loss: 0.3384 - accuracy: 0.8432 - val_loss: 0.4385 - val_accuracy: 0.7719\n",
      "1\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 112s 390ms/step - loss: 1.0481 - accuracy: 0.5984 - val_loss: 0.5962 - val_accuracy: 0.6879\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.5953 - accuracy: 0.6961 - val_loss: 0.5477 - val_accuracy: 0.7247\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.5370 - accuracy: 0.7333 - val_loss: 0.4974 - val_accuracy: 0.7360\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.5014 - accuracy: 0.7545 - val_loss: 0.4963 - val_accuracy: 0.7343\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.4949 - accuracy: 0.7584 - val_loss: 0.4792 - val_accuracy: 0.7622\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.4748 - accuracy: 0.7740 - val_loss: 0.4816 - val_accuracy: 0.7552\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.4564 - accuracy: 0.7824 - val_loss: 0.4924 - val_accuracy: 0.7465\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4822 - val_accuracy: 0.7710\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.4474 - accuracy: 0.7851 - val_loss: 0.4660 - val_accuracy: 0.7561\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.4410 - accuracy: 0.7835 - val_loss: 0.4952 - val_accuracy: 0.7343\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.4329 - accuracy: 0.7973 - val_loss: 0.4780 - val_accuracy: 0.7719\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.4260 - accuracy: 0.7999 - val_loss: 0.5291 - val_accuracy: 0.7649\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.4057 - accuracy: 0.8055 - val_loss: 0.4811 - val_accuracy: 0.7596\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 0.3855 - accuracy: 0.8256 - val_loss: 0.4729 - val_accuracy: 0.7736\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.3620 - accuracy: 0.8344 - val_loss: 0.5045 - val_accuracy: 0.7815\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.3508 - accuracy: 0.8418 - val_loss: 0.5165 - val_accuracy: 0.7614\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.3371 - accuracy: 0.8517 - val_loss: 0.5364 - val_accuracy: 0.7719\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.3054 - accuracy: 0.8607 - val_loss: 0.5505 - val_accuracy: 0.7561\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.2984 - accuracy: 0.8682 - val_loss: 0.5414 - val_accuracy: 0.7753\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.2557 - accuracy: 0.9014 - val_loss: 0.5526 - val_accuracy: 0.7526\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.2281 - accuracy: 0.9037 - val_loss: 0.5912 - val_accuracy: 0.7517\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.2246 - accuracy: 0.9135 - val_loss: 0.8484 - val_accuracy: 0.7622\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1922 - accuracy: 0.9256 - val_loss: 0.6057 - val_accuracy: 0.7631\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1696 - accuracy: 0.9357 - val_loss: 0.6529 - val_accuracy: 0.7614\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1687 - accuracy: 0.9324 - val_loss: 0.6847 - val_accuracy: 0.7491\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1243 - accuracy: 0.9559 - val_loss: 0.8783 - val_accuracy: 0.7517\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1253 - accuracy: 0.9520 - val_loss: 0.8067 - val_accuracy: 0.7570\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1146 - accuracy: 0.9589 - val_loss: 0.8912 - val_accuracy: 0.7404\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.1056 - accuracy: 0.9600 - val_loss: 0.8472 - val_accuracy: 0.7666\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.0886 - accuracy: 0.9669 - val_loss: 0.8358 - val_accuracy: 0.7517\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 111s 388ms/step - loss: 0.0988 - accuracy: 0.9636 - val_loss: 0.8946 - val_accuracy: 0.7491\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 0.1040 - accuracy: 0.9571 - val_loss: 1.0610 - val_accuracy: 0.7404\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 0.0740 - accuracy: 0.9725 - val_loss: 1.1157 - val_accuracy: 0.7491\n",
      "Epoch 34/50\n",
      "139/286 [=============>................] - ETA: 54s - loss: 0.0628 - accuracy: 0.9740"
     ]
    }
   ],
   "source": [
    "# Fit models and store result\n",
    "nameOfTraining = \"Base training, from scratch (50 ep), nth run ()\"\n",
    "for hpId, hpSettings in hyperparametersToUse.items():    \n",
    "    try:\n",
    "        model = modelCreate(hpSettings)\n",
    "        elapsedTime = 0\n",
    "        timeStart = time.time()\n",
    "        # Fit model\n",
    "        history = model.fit(trainBatches,\n",
    "            steps_per_epoch=len(trainBatches),\n",
    "            validation_data=validBatches,\n",
    "            validation_steps=len(validBatches),\n",
    "            epochs=50,\n",
    "            verbose=1\n",
    "        )\n",
    "        elapsedTime = time.time() - timeStart\n",
    "        db = PGCON()\n",
    "        numRows = db.insertRow(\"insert into californium.traininglogs (\\\"name\\\", \\\"data\\\", \\\"hyperparameters\\\", \\\"timeelapsed\\\") values ('\" + nameOfTraining + \"', '\" + json.dumps(history.history) + \"','\" + json.dumps(hpSettings) + \" ', \" + str(elapsedTime) + \");\")\n",
    "        print(numRows)\n",
    "    except:\n",
    "        print('Exception encountered')\n",
    "        db = PGCON()\n",
    "        numRows = db.insertRow(\"insert into californium.traininglogs (\\\"name\\\", \\\"data\\\", \\\"hyperparameters\\\") values ('\" + nameOfTraining + \"', '\" + json.dumps({'Exception':0}) + \"', '\" + json.dumps(hpSettings) + \"');\")\n",
    "        print(numRows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the held-out testset\n",
    "result = model.evaluate(testBatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = model.predict(x=testBatches, steps=len(testBatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
